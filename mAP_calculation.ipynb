{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80fde3d3-87f6-4367-8722-7dbb134bd013",
   "metadata": {},
   "source": [
    "# Load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ede6e7-2794-43d1-af6c-b45220055c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pandas as pd, json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.eval_utils import (\n",
    "    polygonann2objdetect,\n",
    "    coordinates_to_masks,\n",
    "    get_oid_dict_gt,\n",
    "    make_gt_dict_from_dataframe,\n",
    "    subm_to_pred_df,\n",
    "    get_oid_dict_pred,\n",
    "    get_oid_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb6f2b-5a57-4c0a-87b8-75785cc3bbba",
   "metadata": {},
   "source": [
    "# Load Ground Truth Data\n",
    "Description: Make ground truth data in dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c1456-0f3d-416d-a90f-7a39b568a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load directory configurations\n",
    "data_dir = './data'\n",
    "data_dir_eval = os.path.join(data_dir, 'k3_datasets')\n",
    "submission_dir = os.path.join(data_dir_eval, 'kaggle-3-competition-dataset', 'winning_teams_final_submissions')\n",
    "data_dir_kaggle = os.path.join(data_dir, 'kaggle')\n",
    "submission_dir = os.path.join(data_dir_eval, 'kaggle-3-competition-dataset/winning_teams_final_submissions/')\n",
    "\n",
    "# Load GT dataframe\n",
    "df_solution = pd.read_csv(os.path.join(data_dir_eval, 'kaggle-3-competition-dataset', 'host_solution_file.csv'))\n",
    "# convert to valid format\n",
    "df_gt_obj = make_gt_dict_from_dataframe(df_solution)\n",
    "# convert to dictionary format\n",
    "gt_dicts = get_oid_dict_gt(df_gt_obj)\n",
    "print('GT dictionary created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655589b5-9da4-4310-822c-527a26d0b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of images\n",
    "print(\"# of images:\", len(gt_dicts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2201c1f-d7cf-4b3d-a6e9-37278051cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 image_ids\n",
    "print(\"first 10 image_ids: \", list(gt_dicts.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d7cca-c72b-4595-982b-f8c0c0ced6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the component (value) of the gt_dicts\n",
    "sample_id = list(gt_dicts.keys())[0]\n",
    "print(\"Components of gt_dicts for each sample: \", gt_dicts[sample_id].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa2370-484b-4ff9-8775-8712666115d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruth_boxes - has dimension as (n_objects, bbox)\n",
    "gt_dicts[sample_id]['groundtruth_boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af9e1b-d2c9-4dc5-bec8-e5b409b992c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruth_classes - all objects are blood_vessel\n",
    "len(gt_dicts[sample_id]['groundtruth_classes']), set(gt_dicts[sample_id]['groundtruth_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9a6fa-201b-4ba9-8ade-b375c7d8fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruth_group_of, groundtruth_image_classes - this is just dummy. there is no hierarchical structure in this dataset\n",
    "\n",
    "# groundtruth_instance_masks - has dimension as (n_objects, img_height, img_width). This shows the mask of each instances\n",
    "print(gt_dicts[sample_id]['groundtruth_instance_masks'].shape)\n",
    "sample_instance_mask = gt_dicts[sample_id]['groundtruth_instance_masks']\n",
    "background = np.zeros((1, *sample_instance_mask.shape[1:]))\n",
    "sample_instance_mask_with_background = np.concatenate([background, sample_instance_mask])\n",
    "plt.imshow(np.argmax(sample_instance_mask_with_background, axis = (0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cab6a6-da00-4ba3-af3a-bc691611259d",
   "metadata": {},
   "source": [
    "# Calculate mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453ef67-7937-4d21-b554-58f69c5d8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate IoU thresholds for COCOmAP - out target IoU is 0.6, which is already there in this\n",
    "list_iou = np.arange(0.5, 1, 0.05)\n",
    "metrics_by_iou = {\n",
    "    threshold: {}\n",
    "    for threshold in list_iou\n",
    "}\n",
    "# Load submission dataframe\n",
    "list_files_submission = glob.glob(os.path.join(submission_dir, '*.csv'))\n",
    "# for each submission files, calculate the mAP\n",
    "list_valid_ids = sorted(df_solution['id'].values)\n",
    "for file_submission in list_files_submission:\n",
    "    print(f'Calculating mAPs using {file_submission}')\n",
    "    # Load submission file\n",
    "    df_submission = pd.read_csv(file_submission)\n",
    "    # make sure only loading valid images\n",
    "    df_submission = df_submission.loc[df_submission['id'].apply(lambda x: x in list_valid_ids)]\n",
    "    # convert submission to prediction dataframe\n",
    "    df_pred = subm_to_pred_df(df_submission)\n",
    "    # convert prediction dataframe to dictionary format\n",
    "    pred_dicts = get_oid_dict_pred(df_pred)\n",
    "    print('Prediction dictionary loaded... Calculating mAPs')\n",
    "    # get performance\n",
    "    dict_metrics = get_oid_metrics(gt_dicts, pred_dicts, list_iou)\n",
    "    for threshold, metrics in dict_metrics.items():\n",
    "        # get team name\n",
    "        filename = os.path.basename(file_submission)\n",
    "        metrics_by_iou[threshold][filename] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c318e-0426-4701-8c5f-001668e09b61",
   "metadata": {},
   "source": [
    "# Patch-wise mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05e6e7-dd0d-4eff-8517-994ec9e2214a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj_detection",
   "language": "python",
   "name": "obj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
